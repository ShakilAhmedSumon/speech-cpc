{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9UwHE06UJYjar7g8h/Tc9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShakilAhmedSumon/speech-cpc/blob/main/CPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fIN_iaxM8Z5_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "from random import shuffle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import logging\n",
        "import warnings\n",
        "from random import shuffle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_logging(fname, level=logging.DEBUG):\n",
        "    \"\"\"\n",
        "    Create logger instance\n",
        "    :param fname: name of log file\n",
        "    :param level: log level\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    formatter = logging.Formatter('[%(levelname)s]%(asctime)s:%(name)s:%(message)s')\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(level)\n",
        "\n",
        "    # File Handler\n",
        "    fh = logging.FileHandler(fname)\n",
        "    fh.setLevel(level)\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "\n",
        "    # Stream Handler\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.WARNING)\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "5_e6gOkf-ZqF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveDataGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, data_pth='../data', batch_size=10, shuffle=True, seed=42, categories=list(), normalize=True,\n",
        "                 fs=16000, chunk_size=4096, context_samples=5, contrastive_samples=1):\n",
        "        \"\"\"\n",
        "        Constructor\n",
        "\n",
        "        :param data_file: path to data file\n",
        "        :param meta_file:  path to meta file\n",
        "        :param batch_size: batch size\n",
        "        :param measurement_ids: list of measurement ids. Dedicated for CV\n",
        "        :param shuffle:\n",
        "        :param seed: random seed\n",
        "        :param test_mode: return samples and signal_ids\n",
        "        :param normalize: to normalize the data\n",
        "        \"\"\"\n",
        "        self.it = 0\n",
        "        self.shuffle = shuffle\n",
        "        self.data_pth = data_pth\n",
        "        self.normalize = normalize\n",
        "        self.fs = fs\n",
        "        self.batch_size = batch_size\n",
        "        self.seed = seed\n",
        "        self.context_samples = int(context_samples)\n",
        "        self.contrastive_samples = int(contrastive_samples)\n",
        "        self.chunk_size = int(chunk_size)\n",
        "\n",
        "        # Extract list of files from csv\n",
        "        file_list = pd.read_csv(os.path.join(data_pth, 'train_curated.csv'))\n",
        "        if len(categories) == 0:\n",
        "            self.file_list = file_list.fname.tolist()\n",
        "        else:\n",
        "            self.file_list = file_list.query('labels in @categories').fname.tolist()\n",
        "        self.list_sz = len(self.file_list)\n",
        "        self.max_it = int(np.ceil(self.list_sz / self.batch_size))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.max_it\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Performs at the end of each epoch\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        l = self.file_list\n",
        "        shuffle(l)\n",
        "        self.file_list = l\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Return one batch\n",
        "        :param item:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return self.__data_generation(item)\n",
        "\n",
        "    def __data_generation(self, it):\n",
        "        \"\"\"\n",
        "        Data generator\n",
        "        :param it:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        pos = np.minimum(it * self.batch_size, self.list_sz)\n",
        "        frames = (self.contrastive_samples+self.context_samples)*self.chunk_size\n",
        "\n",
        "        i = 0\n",
        "        context_batch = np.zeros([self.batch_size, self.context_samples, self.chunk_size])\n",
        "        contrastive_batch = np.zeros([self.batch_size, self.contrastive_samples, self.chunk_size])\n",
        "\n",
        "        while i < self.batch_size:\n",
        "            fname = self.file_list[pos]\n",
        "            pos = (pos+1) % self.list_sz\n",
        "            signal, sr = librosa.load(os.path.join(self.data_pth, fname), sr=self.fs)\n",
        "            if signal.shape[0]-frames < 0:\n",
        "                logging.getLogger(__name__).info(' File {:s} is too short'.format(fname))\n",
        "            else:\n",
        "                random_shift = np.random.randint(signal.shape[0]-frames)\n",
        "                batch = signal[random_shift:(frames + random_shift)].reshape((-1, self.chunk_size), order='C')\n",
        "                context_batch[i, :, :] = batch[:self.context_samples, :]\n",
        "                contrastive_batch[i, :, :] = batch[self.context_samples:self.context_samples+self.contrastive_samples, :]\n",
        "                i +=1\n",
        "\n",
        "        # shuffle data\n",
        "        #idx = np.random.choice(range(self.batch_size), self.batch_size, replace=False)\n",
        "        #contrastive_batch = contrastive_batch[idx, :, :]\n",
        "        labels=np.zeros([self.batch_size, self.batch_size])\n",
        "        labels=np.identity(self.batch_size)\n",
        "        labels = labels[:, :, np.newaxis]\n",
        "        #labels[range(self.batch_size), idx] = 1\n",
        "        s = ([context_batch[:, :, :, np.newaxis], contrastive_batch[:, :, :, np.newaxis]], labels)\n",
        "        return s"
      ],
      "metadata": {
        "id": "98VH5wh__I2i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SDmOsZ4p_SoZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}